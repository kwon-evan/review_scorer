{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(message)s\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LOAD DATA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.getcwd() + '/review_scorer/data/'\n",
    "SENTI_PATH = DATA_FOLDER + 'SentiWord_info.json'\n",
    "DATA_PATH = DATA_FOLDER + 'data_origin.csv'\n",
    "data: pd.DataFrame\n",
    "\n",
    "with open(SENTI_PATH, mode='rt', encoding='UTF8') as f:\n",
    "    senti = pd.DataFrame.from_dict(json.load(f))\n",
    "\n",
    "data = pd.read_csv(DATA_PATH, encoding='UTF8')\n",
    "data = data.dropna(axis=0)\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TOKENIZER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 71904/71904 [08:36<00:00, 139.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from twkorean import TwitterKoreanProcessor\n",
    "\n",
    "processor = TwitterKoreanProcessor()\n",
    "tokenize = processor.tokenize_to_strings\n",
    "tokens = [tokenize(_) for _ in tqdm(data.review)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SET REVIEW SCORER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting all words and their counts\n",
      "PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "PROGRESS: at sentence #10000, processed 1101910 words, keeping 28163 word types\n",
      "PROGRESS: at sentence #20000, processed 2200031 words, keeping 37331 word types\n",
      "PROGRESS: at sentence #30000, processed 3296263 words, keeping 43244 word types\n",
      "PROGRESS: at sentence #40000, processed 4396701 words, keeping 47564 word types\n",
      "PROGRESS: at sentence #50000, processed 5475354 words, keeping 49702 word types\n",
      "PROGRESS: at sentence #60000, processed 6538131 words, keeping 50953 word types\n",
      "PROGRESS: at sentence #70000, processed 7627974 words, keeping 51655 word types\n",
      "collected 51667 word types from a corpus of 7833944 raw words and 71904 sentences\n",
      "Creating a fresh vocabulary\n",
      "ReviewScorer lifecycle event {'msg': 'effective_min_count=5 retains 22483 unique words (43.52% of original 51667, drops 29184)', 'datetime': '2022-08-10T14:20:36.775294', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "ReviewScorer lifecycle event {'msg': 'effective_min_count=5 leaves 7758850 word corpus (99.04% of original 7833944, drops 75094)', 'datetime': '2022-08-10T14:20:36.776157', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "deleting the raw counts dictionary of 51667 items\n",
      "sample=0.001 downsamples 48 most-common words\n",
      "ReviewScorer lifecycle event {'msg': 'downsampling leaves estimated 6253331.339118918 word corpus (80.6%% of prior 7758850)', 'datetime': '2022-08-10T14:20:36.965093', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "estimated required memory for 22483 words and 100 dimensions: 29227900 bytes\n",
      "resetting layer weights\n",
      "ReviewScorer lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-08-10T14:20:37.219802', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'build_vocab'}\n",
      "ReviewScorer lifecycle event {'msg': 'training model with 3 workers on 22483 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-08-10T14:20:37.220726', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'train'}\n",
      "EPOCH 0 - PROGRESS: at 3.11% examples, 191143 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 6.64% examples, 196279 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 0 - PROGRESS: at 9.86% examples, 199653 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 13.42% examples, 204209 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 16.69% examples, 200506 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 0 - PROGRESS: at 20.06% examples, 202227 words/s, in_qsize 6, out_qsize 2\n",
      "EPOCH 0 - PROGRESS: at 23.49% examples, 203624 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 0 - PROGRESS: at 26.84% examples, 204470 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 30.12% examples, 205113 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 33.55% examples, 204867 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 36.71% examples, 204889 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 39.92% examples, 204269 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 43.33% examples, 203446 words/s, in_qsize 4, out_qsize 1\n",
      "EPOCH 0 - PROGRESS: at 46.83% examples, 203916 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 0 - PROGRESS: at 50.07% examples, 203931 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 53.39% examples, 203597 words/s, in_qsize 5, out_qsize 1\n",
      "EPOCH 0 - PROGRESS: at 56.74% examples, 203779 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 60.02% examples, 203900 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 63.29% examples, 203473 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 0 - PROGRESS: at 66.90% examples, 204175 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 70.47% examples, 204498 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 73.99% examples, 204616 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 77.18% examples, 204554 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 80.62% examples, 204554 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 84.06% examples, 204578 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 87.27% examples, 204559 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 90.61% examples, 204400 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 94.03% examples, 204466 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 97.38% examples, 204456 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 0: training on 7833944 raw words (6253331 effective words) took 30.5s, 204852 effective words/s\n",
      "EPOCH 1 - PROGRESS: at 3.00% examples, 194760 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 6.51% examples, 197227 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 9.61% examples, 199187 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 1 - PROGRESS: at 13.13% examples, 203296 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 16.43% examples, 202783 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 19.66% examples, 202760 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 23.12% examples, 203920 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 26.47% examples, 204346 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 29.66% examples, 204340 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 32.94% examples, 204071 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 1 - PROGRESS: at 36.21% examples, 204867 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 39.66% examples, 205022 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 43.11% examples, 204649 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 46.45% examples, 204679 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 1 - PROGRESS: at 49.95% examples, 205103 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 53.39% examples, 205583 words/s, in_qsize 4, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 56.38% examples, 204579 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 59.53% examples, 204549 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 1 - PROGRESS: at 62.93% examples, 204643 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 66.20% examples, 204446 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 1 - PROGRESS: at 69.81% examples, 204812 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 73.25% examples, 204536 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 76.56% examples, 204818 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 79.96% examples, 204742 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 1 - PROGRESS: at 83.54% examples, 204982 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 86.77% examples, 204967 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 90.11% examples, 205073 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 93.51% examples, 205228 words/s, in_qsize 4, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 96.97% examples, 205091 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1: training on 7833944 raw words (6253617 effective words) took 30.4s, 205688 effective words/s\n",
      "EPOCH 2 - PROGRESS: at 3.00% examples, 188649 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 6.50% examples, 196392 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 9.61% examples, 197270 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 13.00% examples, 198709 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 16.43% examples, 200898 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 19.66% examples, 200181 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 2 - PROGRESS: at 23.24% examples, 201239 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 26.62% examples, 202451 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 29.76% examples, 202581 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 33.05% examples, 202251 words/s, in_qsize 5, out_qsize 1\n",
      "EPOCH 2 - PROGRESS: at 36.33% examples, 202390 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 39.64% examples, 202228 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 43.11% examples, 202841 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 46.21% examples, 202044 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 2 - PROGRESS: at 49.67% examples, 202435 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 53.16% examples, 202484 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 2 - PROGRESS: at 56.38% examples, 202513 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 2 - PROGRESS: at 59.77% examples, 203172 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 63.15% examples, 202842 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 2 - PROGRESS: at 66.75% examples, 203681 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 70.04% examples, 203290 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 73.65% examples, 203697 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 76.94% examples, 203730 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 80.36% examples, 203622 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 83.94% examples, 203723 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 2 - PROGRESS: at 87.27% examples, 203807 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 90.63% examples, 204122 words/s, in_qsize 4, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 93.92% examples, 203679 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 97.38% examples, 203875 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2: training on 7833944 raw words (6253708 effective words) took 30.6s, 204290 effective words/s\n",
      "EPOCH 3 - PROGRESS: at 3.11% examples, 198992 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 6.63% examples, 203021 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 9.75% examples, 202536 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 13.42% examples, 207785 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 16.54% examples, 205281 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 20.06% examples, 206760 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 23.49% examples, 205300 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 3 - PROGRESS: at 26.83% examples, 205652 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 3 - PROGRESS: at 30.12% examples, 205765 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 33.55% examples, 206229 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 36.71% examples, 205538 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 40.33% examples, 206133 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 43.73% examples, 206128 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 47.08% examples, 206108 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 50.60% examples, 206064 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 53.97% examples, 205891 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 57.37% examples, 205799 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 60.56% examples, 205366 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 3 - PROGRESS: at 63.89% examples, 205538 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 67.35% examples, 205173 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 70.93% examples, 205428 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 74.28% examples, 204977 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 3 - PROGRESS: at 77.55% examples, 205118 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 3 - PROGRESS: at 81.04% examples, 204940 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 3 - PROGRESS: at 84.46% examples, 204872 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 3 - PROGRESS: at 87.75% examples, 204763 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 3 - PROGRESS: at 91.16% examples, 205011 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 94.42% examples, 204723 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 97.89% examples, 204712 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 3: training on 7833944 raw words (6253053 effective words) took 30.5s, 205282 effective words/s\n",
      "EPOCH 4 - PROGRESS: at 3.03% examples, 186593 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 4 - PROGRESS: at 6.77% examples, 201051 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 9.99% examples, 202153 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 4 - PROGRESS: at 13.39% examples, 203764 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 16.80% examples, 203530 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 20.19% examples, 203568 words/s, in_qsize 6, out_qsize 1\n",
      "EPOCH 4 - PROGRESS: at 23.60% examples, 204181 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 27.08% examples, 204733 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 30.22% examples, 204321 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 33.80% examples, 205223 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 36.96% examples, 204472 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 40.45% examples, 204883 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 43.73% examples, 204350 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 47.07% examples, 204459 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 50.33% examples, 204042 words/s, in_qsize 5, out_qsize 1\n",
      "EPOCH 4 - PROGRESS: at 53.73% examples, 204175 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 57.12% examples, 204227 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 60.44% examples, 204478 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 63.63% examples, 204281 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 67.07% examples, 203565 words/s, in_qsize 6, out_qsize 2\n",
      "EPOCH 4 - PROGRESS: at 71.06% examples, 204390 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 74.64% examples, 204838 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 77.81% examples, 204424 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 81.41% examples, 204601 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 84.96% examples, 204596 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 88.24% examples, 204769 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 91.55% examples, 204281 words/s, in_qsize 4, out_qsize 1\n",
      "EPOCH 4 - PROGRESS: at 95.04% examples, 204580 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 98.36% examples, 204337 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4: training on 7833944 raw words (6252785 effective words) took 30.6s, 204669 effective words/s\n",
      "ReviewScorer lifecycle event {'msg': 'training on 39169720 raw words (31266494 effective words) took 152.6s, 204931 effective words/s', 'datetime': '2022-08-10T14:23:09.792311', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'train'}\n",
      "ReviewScorer lifecycle event {'params': 'ReviewScorer<vocab=22483, vector_size=100, alpha=0.025>', 'datetime': '2022-08-10T14:23:09.793339', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from review_scorer import ReviewScorer\n",
    "\n",
    "# Review scorer needs tokens of datas to train when initializing it.\n",
    "# 리뷰 채점기 클래스를 생성할 때, 토크나이즈 된 데이터를 인자로 주어야 합니다.\n",
    "rs = ReviewScorer(sentences=tokens, senti_dict_path=SENTI_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAGGING RIVIEW SCORER's SENTIMENTAL DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taste tagged\n",
      "price tagged\n",
      "service tagged\n",
      "atmosphere tagged\n"
     ]
    }
   ],
   "source": [
    "# Tagging review scorer's sentimental dictionary by category.\n",
    "# 카테고리에 따라 리뷰 채점기의 감성사전을 태깅합니다.\n",
    "rs.tag(categories={'taste': ['맛', '맛있다', '맛없다'],\n",
    "                   'price': ['가격', '싸다', '비싸다', '저렴'],\n",
    "                   'service': ['서비스', '친절', '싸가지'],\n",
    "                   'atmosphere': ['인테리어', '분위기']}, topn=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORING WITH REVIEW SCORER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  50000\n",
      "{'taste': 7, 'price': 4, 'service': 3, 'atmosphere': 2}\n",
      "#을지로 #입정동 #을지면옥\"맛의 대향연이였던 냉면 한 그릇\"1. 을지면옥을 방문한지 3년이 훌쩍 넘었다. 2017년 당시 너무 짜진 육수에 실망을 했으나 술안주로 먹기에는 적절한 간이라 나쁘지는 않았던 것 같다.영하 10도가 넘는 칼바람이 불던 날, 을지로길을 걷다 발견한 을지면옥의 올드스쿨 바이브 가득한 간판에 이끌려 예전과 많이 달라졌나 궁금해 냉면 한 그릇 청했다.2. 의정부 평양면옥의 특징인 고추가루가 솔솔 올라간 냉면 한 그릇이 서빙이 됐는데, 지금까지는 몰랐던 냉면 그릇의 사이즈에 깜짝 놀랐다.생각보다 큰데다 양도 상당하다. 보통 냉면 먹을 때 육수 먼저 원샷으로 끝내고 추가 육수 받아 다시 시작하는데 이집은 그럴 필요가 없을 정도로 육수와 국수의 양이 넉넉하다.을밀대 본점에서 \"양많이\"로 주문하면 나오는 그 정도의 양이 기본으로 서빙이 된다.가격이 12,000원이라 왠지 그만큼은 먹어야 본전이 될 것 같은 느낌이 들기도 하지만 ㅎㅎㅎ3. 맑은 국물과는 대조적으로 육향이 굉장이 진하고 간도 간간하다. 예전보다는 좀 더 순화된 간이지만 결코 전에 비해 덜짜졌다고 말하긴 어렵다.그런데 맛이 폭발한다. 먼저 육수는 육향도 진하고 간도 있지만 감칠맛도 강하다. 거부감 스러운 감칠맛은 아니지만 차가운 곰탕을 먹는 듯한 맛이다.이집 메뉴에 소고기국밥이 있는데, 요즘 여기 육수 스타일을 보면 맛있을 것 같다.4. 면을 살살 풀어서 육수에 곡기를 주고 마시면 또다른 맛이다. 감칠맛이 순화되서 부드럽고 고급스러운 맛으로 변한다.면은 겨울이라서 그런지 메밀향이 꽤 좋다. 감칠맛 육수가 묻어 있는 메밀향 좋은 면빨은 행복 그 자체다.그런데 여기서 끝나지 않고 가끔 톡톡 씹히는 참깨의 고소함이 일품이다. 필동면옥도 참깨를 좀 올리지만 을지면옥의 참깨 양이 압도적으로 많아 참깨의 고소함을 씹을 확률이 더 높다.더불어 씹히는 고추가루의 알싸한 맛까지 합쳐지니 이전에 못느꼈던 <을지면옥만의 냉면맛>이 정립이 된다.5. 게다가 제육고명과 아롱사태 고명도 고기맛을 진하게 품고 있어 낮에 간식하러 들어왔다 쏘주를 주문할 뻔 했다 ㅎㅎ맛있게 한 그릇 비우고 면수로 몸을 따듯하게 덥혀주고 나오는 길에 이런 생각이 들었다.<냉면의 맛은 판단하는 것이 아니다.... 그져 그집의 냉면을 즐기면 될 뿐...>\n",
      "\n",
      "index:  50001\n",
      "{'taste': 2, 'price': 2, 'service': 0, 'atmosphere': 0}\n",
      "피자 맛있음 진짜 정말 맛있음!! 가게 분위기도 좋은데 가게 찾는게 좀 어려웠음. 또 가고싶다\n",
      "\n",
      "index:  50002\n",
      "{'taste': 1, 'price': 0, 'service': 1, 'atmosphere': 0}\n",
      "미쉐린에 뽑힐 만큼의 육회 맛집인지는 모르겠다. 저렴한 가격에 부담없이 가성비 괜찮은 육회집인것만은 분명~\n",
      "\n",
      "index:  50003\n",
      "{'taste': 2, 'price': -2, 'service': 0, 'atmosphere': 0}\n",
      "역시 망플픽은 실패하지 않는듯곰탕이지만 우리가 알던 하얀국물이 아닌 맑은 국물이 특징숟가락으로 국물을 떠먹으면 멈출수 없어 바닥까지 설거지하게됨곰탕 특(10,000원) 기준으로 고기는 두툼한 덩이 5-6개정도가 나오는데, 간이 되어있는 한우 고기로 짭잘하고 매우 맛있음개인적으로 소면은 약간 퍼진듯한 느낌으로 조금 아쉬웠음! 맛있어서 이주동안 두번 방문한집!\n",
      "\n",
      "index:  50004\n",
      "{'taste': 16, 'price': 12, 'service': 0, 'atmosphere': 2}\n",
      "맛있고 재미있다. 이런게 연남동에 대한 아재의 기대.어느날부터 연남동 가기가 미안(?)하다.초 젊은이들이 활보하는데 뷰를 망치는 것 같아서.하긴 어차피 솔직히 연남동 식당들 중 새로 생긴 곳들은 어차피 날 타겟하지도 않는 것 같아 맘 편하기도 함.(수많은 연어집들..)그럼에도 가끔 연남동을 가는 이유는,오래된 맛집들, 혹은 재밌고 신선한 집들이 대한 기대.이 집이 두가질 다 충족했다.소금으로 간했다는 청 냉면(간장으로 간을 한 버전도 있음)은 국물도 맑고 시원했고, 면도 적당히 꼬들하게 술술 흡입됐다.어복쟁반은 전통적인 것들과 비주얼은 달랐으나, 향긋한 표고와 야채들이 어우러져 수육같기도, 샤브샤브 같기도 한 오묘한 느낌을 줬다.초기 팩소주를 팔았다는데, 지금은 조금 고급 술들을 취급. 잔술 두 잔 시켰는데 토끼소주 12,000원, 문배주 8,000원임. 다소 비싸긴 하나, 좋은 수익 모델 같기도 했다. 담에 혼자 오면 잔술 한잔에 냉면 한그릇 먹을 듯.실내는 큰 ㄷ 자형의 바 형태. 조명은 약간 어두운 편. 마주 앉는 형태가 아니라 그런가 과음하는 사람들은 없다 ㅎ자주 생각날 듯한 집. 추천!\n",
      "\n",
      "index:  50005\n",
      "{'taste': 11, 'price': 8, 'service': 2, 'atmosphere': 0}\n",
      "도토리를 좋아하는 사람이면 꼭꼭 가보길 바란다!2명이서 도토리 쟁반국수와 도토리전을 주문했는데 양이 진~~짜 많아서 전은 포장했다!쟁반국수는 매콤한 비빔양념과 잣, 오이 등과 같은 각종 야채, 파인애플, 계란이 쫄깃한 도토리면과 어우러져 나온다~기다란 도토리면 뿐만 아니라 납작한 수제비 모양 면도 있는데 쫄깃쫄깃해서 먹는 식감이 좋았다!도토리전은 새우, 버섯 등의 재료가 도토리가루와 함께 부쳐져 나오는데 일단 사이즈가 굉장히 크다...!속재료도 풍부하고 타지 않을 정도로 바삭하게 구워져서 정말 맛있었다~주말 저녁에는 웨이팅이 있을 수 있고 주차장은 가게 주차장이 다 찰 경우, 옆 된장가게와 공터에 주차할 수 있다!\n",
      "\n",
      "index:  50006\n",
      "{'taste': -1, 'price': -1, 'service': -2, 'atmosphere': 0}\n",
      "고기는 너무 비싸서 냉면만 먹고 왔는데 정말 맛있었어요! 가격이 좀 비싼게 흠이지만 평양냉면 가격이 보통 8,9천원정도 한다고 생각하면 많이 비싸게 느껴지지 않는게 좀 위안이 되네요. 좀 비싸도 전혀 돈 아깝지 않았네요\n",
      "\n",
      "index:  50007\n",
      "{'taste': 4, 'price': 4, 'service': 0, 'atmosphere': 0}\n",
      "ㅎㅎㅎㅎ저는 바베큐 스타일이 저랑 안 맞는것 같아서 낮은 점수드렸는데 워낙 유명하고 별점 많으니까 궁금하시면 다녀오세요~! 찐 야생 바베큐 불맛!!! 그리고 저희는 파이가 너무 타서 딱딱 했네요 ㅠㅠㅠ 새우는 넘나크고 알찼어요ㅎㅎㅎ\n",
      "\n",
      "index:  50008\n",
      "{'taste': 1, 'price': 1, 'service': 1, 'atmosphere': 0}\n",
      "감자만두는 그냥 그랬고 죽이랑 칼국수는 괜찮았어요.\n",
      "\n",
      "index:  50009\n",
      "{'taste': 6, 'price': 6, 'service': 6, 'atmosphere': 0}\n",
      "너무나도 유명한 집이 압구정으로 옮겨져서 드디어 가봤다.명성이 큰만큼 기대도 컸던 탓일까 내 입맛엔 그냥그냥나쁘지는 않았지만 오히려 카츠보다은 다츠다아게가 훨 훌륭했다가볼만한 곳이지만 큰 기대는 안하면 더더 만족할 것 같다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = 50000\n",
    "for i in range(start, start + 10):\n",
    "    print('index: ', i)\n",
    "    print(rs.score_review(tokenize(data.review.iloc[i])))\n",
    "    print(data.review.iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}