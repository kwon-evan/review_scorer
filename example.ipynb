{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "date_strftime_format = \"%Y-%m-%y %H:%M:%S\"\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(asctime)s %(message)s\", datefmt=date_strftime_format)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LOAD DATA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.getcwd() + '/review_scorer/data/'\n",
    "SENTI_PATH = DATA_FOLDER + 'SentiWord_info.json'\n",
    "DATA_PATH = DATA_FOLDER + 'data_origin.csv'\n",
    "data: pd.DataFrame\n",
    "\n",
    "with open(SENTI_PATH, mode='rt', encoding='UTF8') as f:\n",
    "    senti = pd.DataFrame.from_dict(json.load(f))\n",
    "\n",
    "data = pd.read_csv(DATA_PATH, encoding='UTF8')\n",
    "data = data.dropna(axis=0)\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TOKENIZER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 29557/29557 [03:25<00:00, 143.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from twkorean import TwitterKoreanProcessor\n",
    "\n",
    "processor = TwitterKoreanProcessor()\n",
    "tokenize = processor.tokenize_to_strings\n",
    "tokens = [tokenize(_) for _ in tqdm(data.review)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SET REVIEW SCORER"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-22 13:43:36 collecting all words and their counts\n",
      "2022-08-22 13:43:36 PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/pytorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-22 13:43:42 PROGRESS: at sentence #10000, processed 1119791 words, keeping 30365 word types\n",
      "2022-08-22 13:43:49 PROGRESS: at sentence #20000, processed 2237102 words, keeping 42611 word types\n",
      "2022-08-22 13:43:55 collected 51667 word types from a corpus of 3315605 raw words and 29557 sentences\n",
      "2022-08-22 13:43:55 Creating a fresh vocabulary\n",
      "2022-08-22 13:43:55 Doc2Category lifecycle event {'msg': 'effective_min_count=5 retains 15230 unique words (29.48% of original 51667, drops 36437)', 'datetime': '2022-08-17T13:43:55.372670', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "2022-08-22 13:43:55 Doc2Category lifecycle event {'msg': 'effective_min_count=5 leaves 3260723 word corpus (98.34% of original 3315605, drops 54882)', 'datetime': '2022-08-17T13:43:55.373568', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "2022-08-22 13:43:55 deleting the raw counts dictionary of 51667 items\n",
      "2022-08-22 13:43:55 sample=0.001 downsamples 48 most-common words\n",
      "2022-08-22 13:43:55 Doc2Category lifecycle event {'msg': 'downsampling leaves estimated 2621766.0700681433 word corpus (80.4%% of prior 3260723)', 'datetime': '2022-08-17T13:43:55.495265', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'prepare_vocab'}\n",
      "2022-08-22 13:43:55 estimated required memory for 15230 words and 100 dimensions: 19799000 bytes\n",
      "2022-08-22 13:43:55 resetting layer weights\n",
      "2022-08-22 13:43:55 Doc2Category lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-08-17T13:43:55.664082', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'build_vocab'}\n",
      "2022-08-22 13:43:55 Doc2Category lifecycle event {'msg': 'training model with 3 workers on 15230 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-08-17T13:43:55.664828', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'train'}\n",
      "2022-08-22 13:43:56 EPOCH 0 - PROGRESS: at 7.01% examples, 183513 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:43:57 EPOCH 0 - PROGRESS: at 15.21% examples, 195111 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:43:58 EPOCH 0 - PROGRESS: at 23.80% examples, 202666 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:43:59 EPOCH 0 - PROGRESS: at 32.16% examples, 203888 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:00 EPOCH 0 - PROGRESS: at 40.00% examples, 203234 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:01 EPOCH 0 - PROGRESS: at 47.85% examples, 202669 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:02 EPOCH 0 - PROGRESS: at 55.69% examples, 201758 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:03 EPOCH 0 - PROGRESS: at 64.32% examples, 202897 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:04 EPOCH 0 - PROGRESS: at 72.26% examples, 203196 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:06 EPOCH 0 - PROGRESS: at 80.76% examples, 202772 words/s, in_qsize 6, out_qsize 2\n",
      "2022-08-22 13:44:07 EPOCH 0 - PROGRESS: at 88.85% examples, 203327 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:08 EPOCH 0 - PROGRESS: at 96.97% examples, 203456 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:08 EPOCH 0: training on 3315605 raw words (2621922 effective words) took 12.8s, 204615 effective words/s\n",
      "2022-08-22 13:44:09 EPOCH 1 - PROGRESS: at 7.31% examples, 193028 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:10 EPOCH 1 - PROGRESS: at 15.21% examples, 199770 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:11 EPOCH 1 - PROGRESS: at 23.23% examples, 201435 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:12 EPOCH 1 - PROGRESS: at 31.52% examples, 200614 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:13 EPOCH 1 - PROGRESS: at 39.38% examples, 201037 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:14 EPOCH 1 - PROGRESS: at 47.31% examples, 201271 words/s, in_qsize 4, out_qsize 0\n",
      "2022-08-22 13:44:15 EPOCH 1 - PROGRESS: at 55.73% examples, 203403 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:16 EPOCH 1 - PROGRESS: at 63.19% examples, 202178 words/s, in_qsize 5, out_qsize 1\n",
      "2022-08-22 13:44:17 EPOCH 1 - PROGRESS: at 71.63% examples, 203579 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:18 EPOCH 1 - PROGRESS: at 79.61% examples, 203445 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:19 EPOCH 1 - PROGRESS: at 87.37% examples, 203492 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:20 EPOCH 1 - PROGRESS: at 95.72% examples, 204300 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:21 EPOCH 1: training on 3315605 raw words (2621544 effective words) took 12.8s, 205434 effective words/s\n",
      "2022-08-22 13:44:22 EPOCH 2 - PROGRESS: at 7.30% examples, 186830 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:23 EPOCH 2 - PROGRESS: at 15.81% examples, 199052 words/s, in_qsize 5, out_qsize 1\n",
      "2022-08-22 13:44:24 EPOCH 2 - PROGRESS: at 24.15% examples, 202836 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:25 EPOCH 2 - PROGRESS: at 32.15% examples, 201932 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:26 EPOCH 2 - PROGRESS: at 40.62% examples, 203690 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:27 EPOCH 2 - PROGRESS: at 48.77% examples, 203801 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:28 EPOCH 2 - PROGRESS: at 57.09% examples, 203034 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:29 EPOCH 2 - PROGRESS: at 65.10% examples, 203557 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:30 EPOCH 2 - PROGRESS: at 72.86% examples, 202097 words/s, in_qsize 5, out_qsize 1\n",
      "2022-08-22 13:44:31 EPOCH 2 - PROGRESS: at 81.59% examples, 203181 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:32 EPOCH 2 - PROGRESS: at 89.49% examples, 203606 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:33 EPOCH 2 - PROGRESS: at 97.93% examples, 204600 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:33 EPOCH 2: training on 3315605 raw words (2621674 effective words) took 12.7s, 205662 effective words/s\n",
      "2022-08-22 13:44:35 EPOCH 3 - PROGRESS: at 7.61% examples, 194690 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:36 EPOCH 3 - PROGRESS: at 15.21% examples, 193129 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:37 EPOCH 3 - PROGRESS: at 22.97% examples, 196207 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:38 EPOCH 3 - PROGRESS: at 31.52% examples, 200826 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:39 EPOCH 3 - PROGRESS: at 39.38% examples, 200963 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:40 EPOCH 3 - PROGRESS: at 47.31% examples, 200104 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:41 EPOCH 3 - PROGRESS: at 55.41% examples, 201572 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:42 EPOCH 3 - PROGRESS: at 63.16% examples, 201701 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:43 EPOCH 3 - PROGRESS: at 70.64% examples, 201740 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:44 EPOCH 3 - PROGRESS: at 78.70% examples, 201853 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:45 EPOCH 3 - PROGRESS: at 86.56% examples, 201696 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:46 EPOCH 3 - PROGRESS: at 94.17% examples, 201657 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:46 EPOCH 3: training on 3315605 raw words (2622325 effective words) took 13.0s, 202283 effective words/s\n",
      "2022-08-22 13:44:47 EPOCH 4 - PROGRESS: at 7.30% examples, 188452 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:49 EPOCH 4 - PROGRESS: at 15.21% examples, 198169 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:50 EPOCH 4 - PROGRESS: at 23.17% examples, 201701 words/s, in_qsize 5, out_qsize 0\n",
      "2022-08-22 13:44:51 EPOCH 4 - PROGRESS: at 31.52% examples, 203757 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:52 EPOCH 4 - PROGRESS: at 39.38% examples, 201065 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:53 EPOCH 4 - PROGRESS: at 47.85% examples, 202503 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:54 EPOCH 4 - PROGRESS: at 55.73% examples, 201237 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:55 EPOCH 4 - PROGRESS: at 63.76% examples, 201615 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:56 EPOCH 4 - PROGRESS: at 71.63% examples, 202019 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:57 EPOCH 4 - PROGRESS: at 79.61% examples, 201099 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:58 EPOCH 4 - PROGRESS: at 87.40% examples, 201585 words/s, in_qsize 6, out_qsize 0\n",
      "2022-08-22 13:44:59 EPOCH 4 - PROGRESS: at 95.17% examples, 201174 words/s, in_qsize 6, out_qsize 1\n",
      "2022-08-22 13:44:59 EPOCH 4: training on 3315605 raw words (2622297 effective words) took 12.9s, 202762 effective words/s\n",
      "2022-08-22 13:44:59 Doc2Category lifecycle event {'msg': 'training on 16578025 raw words (13109762 effective words) took 64.2s, 204084 effective words/s', 'datetime': '2022-08-17T13:44:59.902712', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'train'}\n",
      "2022-08-22 13:44:59 Doc2Category lifecycle event {'params': 'Doc2Category<vocab=15230, vector_size=100, alpha=0.025>', 'datetime': '2022-08-17T13:44:59.903524', 'gensim': '4.2.0', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-65-generic-x86_64-with-debian-buster-sid', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from review_scorer import Doc2Category\n",
    "\n",
    "# Review scorer needs tokens of datas to train when initializing it.\n",
    "# 리뷰 채점기 클래스를 생성할 때, 토크나이즈 된 데이터를 인자로 주어야 합니다.\n",
    "model = Doc2Category(sentences=tokens, senti_dict_path=SENTI_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAGGING RIVIEW SCORER's SENTIMENTAL DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "taste: 100%|████████████████████████████████| 1519/1519 [01:31<00:00, 16.65it/s]\n",
      "price: 100%|████████████████████████████████| 2334/2334 [02:20<00:00, 16.56it/s]\n",
      "service: 100%|████████████████████████████████| 728/728 [00:43<00:00, 16.59it/s]\n",
      "atmosphere: 100%|█████████████████████████████| 509/509 [00:30<00:00, 16.62it/s]\n",
      "polarity: 100%|██████████████████████████| 14854/14854 [00:32<00:00, 456.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tagging review scorer's sentimental dictionary by category.\n",
    "# 카테고리에 따라 리뷰 채점기의 감성사전을 태깅합니다.\n",
    "model.tag(categories={'taste': ['맛', '맛있다', '맛없다'],\n",
    "                      'price': ['가격', '싸다', '비싸다', '저렴'],\n",
    "                      'service': ['서비스', '친절', '싸가지'],\n",
    "                      'atmosphere': ['인테리어', '분위기']},\n",
    "          width=6, depth=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORING WITH REVIEW SCORER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  2000\n",
      "{'taste': 8.057142857142857, 'price': 1.0, 'service': -2.0, 'atmosphere': 0.0}\n",
      "한줄평: 가성비 런치 스시도 좋지만, 요리 중심 디너 코스도 최고!런치에 맛있게 스시를 먹었던 와려에 디너에 방문했다. 디너도 스시 쥐어주시는 줄 알았는데, 디너는 요리 중심이었다. 원래도 디너부터 영업했다가 런치 시간이 비니까 스시를 시작하셨던 거라고 한다.- 호박스프하몽 슬라이스가 올라간 호박스프. 마치 스페인에서 먹던 가스파초의 어레인지 버전 같은 맛이다.- 광어 딱새우 가리비 샐러드내가 좋아하는 해산물들이 가득 들어간 샐러드. 광어도 탱글하고 달큰한 딱새우와 부드러운 가리비 최고다!- 우니크림면충격적으로 맛있었던 디쉬. 일본 3대 면이라 불리는 이나니와면을 사용해서 크림소스면. 위에 우니와 캐비어가 올라감. 우니를 잘 으깨 비벼먹어야한다. 우니의 녹진한 맛과 크리미한 이나니와면이 정말 잘 어울려❤- 모듬사시미왼쪽부터 참돔 참치뱃살 잿방어 능섬어 시마아지 밴자리돔. 고급 어종이 가득한 사시미! 네타 상태도 좋고 전부 맛잇다- 맑은국노래미가 들어간 맑은 국- 청보리 리조또전복 내장을 사용한 리조또다. 와려 디너 코스의 시그니처 메뉴 중 하나. 전복 너무 쫜득야들하고, 내장 리조또도 식감이나 맛이나 진짜 맛있다!! 감탄사가 절로남(엄지척)❤- 아지나메로나메로는 일본 치바지역 향토 조리방식으로, 아지나메로는 전갱이를 구워서 잘게 다져서 양념에 버무린 것이다. 와려에서는 된장과 시소랑 버무렸는데, 요걸 김에 싸먹으니 마치 군함마키를 손으로 싸먹는 기분!- 은대구 간장구이중간에 구이 등장. 은대구의 야들야들하고 탱탱한 살점은 말하지 않아도 맛있음. 껍질까지 맛있...- 소고기 시소말이 튀김위에는 우엉튀김이 올라가고, 아래 미소소스가 뿌려졌다. 시소가 향긋하게 향을 내면서 소고기 육즙을 잡아준다. 우엉이 바삭한 식감을 배가시킴.- 장어솥밥비주얼 끝판왕❤ 넘나 먹음직스러운 장어솥밥! 처음에 잘 섞어서 밥을 담아주시는데, 넘 맛있다! 고슬고슬한 밥이랑 잘 구워진 장어랑 조화가 좋다. 어느정도 먹고 나면 오차즈케도 준비해주는데, 요게 또 별미다.런치 스시도 만족스러웠는데, 디너는 오히려 더 여유롭게 다양한 요리를 먹을수 있어서 좋았다! 게다 셰프님 접객 스타일 넘 좋아서 단골이 될것만 같은 기분이야❤instagram @yeh_rang #먹히영\n",
      "\n",
      "index:  2001\n",
      "{'taste': 9.0, 'price': 0.002152852529601722, 'service': 1.9999999999999998, 'atmosphere': 0.0}\n",
      "생소하지만 신선했던 바오! 중국대만식 햄버거 느낌이다. 바오는 꽃빵 안에 여러가지 재료를 넣어 따뜻하게 나오는데 포크바오는 동파육이 입에서 살살 녹는다. 땅콩소스와 직접 담궜다는 피클도 너무 잘어울린다. 트러플바오는 세가지 다른 종류의 버섯과 튀긴 마늘 등이 들어갔는데 두 바오 모두 강추할만한 메뉴다. 동파육파스타는 동파육이 바오보다 부드럽진 않지만 다른 음식점에서 쉽게 맛볼 수 없는 조합이라 먹는 재미가 있었다. 살짝 짭쪼름 하지만 청경채와 먹으면 그저 맛있게 느껴진다. 향신료가 약간 호불호가 갈릴 수 있겠으나 중국음식 좋아한다면 시도해볼만한 메뉴다.트러플 오일로 요리된 트러플감자튀김도 맥주와 잘 어울리고 바삭하니 맛있다.테이블이 그리 많진않아 식사시간에는 만석인 것으로 보인다. 직원분이 메뉴설명도 친절하게 잘 해주셔서 어떤 재료가 들어있는지 알고 먹을 수 있다. 창가 끝자리에 두명이 앉을 수 있는데 아담하고 뷰가 좋아서 연인이 앉으면 좋을 것 같다.\n",
      "\n",
      "index:  2002\n",
      "{'taste': -0.5, 'price': -1.0904761904761906, 'service': 0.0, 'atmosphere': -0.19047619047619047}\n",
      "드디어 뽕족을 먹었습니다ㅜ친구가 유튜브에서 먹방하는데 맨날 이거 시켜먹는 먹방 볼 때마다 군침흘렸어요ㅠㅠ 오향족발 좋아하고 창신동매운족발 좋아하는데 그냥족발 매운족발 반반 모두 잘하는 집을 찾기 힘들더라구요.. 근데 여기는 비주얼부터 촉촉하니ㅜ 엄청 부드러울 것 같아서 기대했는데 딱 기대했던 그 맛!!! 매운 족발이 더 맵고 더 불맛이 나면 좋겠지만 또 적당한 맛도 있는 것 같아요! 보통 웨이팅이 길다고 하는데 저는 일요일저녁에 가서 그런지 엄청 한산했어요.. 여기가 아닌가 싶었음ㅠㅠ 그치만 바로 이맛!!!!\n",
      "\n",
      "index:  2003\n",
      "{'taste': 0, 'price': 0, 'service': 0, 'atmosphere': 0}\n",
      "선택의 여지 없이 토리빠이탄을 먹게 됐다 그런데 세상에 라멘의 새로운 경지를 맛봤고 고명으로 올라가는 닭고기 또한 닭의 새로운 경지였다 고소하고 감칠맛 나는 육수... 가을 겨울에 또 가야지 찬바람 부는 날\n",
      "\n",
      "index:  2004\n",
      "{'taste': 3.0, 'price': 0.0, 'service': 0.0, 'atmosphere': 0.0}\n",
      "와사비가 신선하고 맥주도 좋고 텐동의 그것이 조금 느껴짐\n",
      "\n",
      "index:  2005\n",
      "{'taste': 4.057142857142857, 'price': 2.0, 'service': 0.0, 'atmosphere': 0.0}\n",
      "탄탄키마카레+치킨난반 주문.키마카레를 좋아하는데 탄탄키마는 어떨까 해서 가봤다. 칼칼하거나 마라느낌의 탄탄은 아니고 첨면장, 즈마장이 들어간 고소하고 달달한 맛이었다. 캐슈넛 크림도 들어가서 전반적으로 부드럽고 달달한 맛. 토치해서 내주는 치즈밥에서는 불맛이 남. 맛있게 먹었다. 치킨난반은 타르타르 소스도 좋고 난반 소스가 있어서 느끼할수도 있는 맛을 잘 잡아준다. 닭튀김 자체도 맛있고 소스들의 조화도 좋았다.\n",
      "\n",
      "index:  2006\n",
      "{'taste': 5.7, 'price': -0.9904761904761905, 'service': 0.0, 'atmosphere': -0.19047619047619047}\n",
      "드디어 다녀온 대성집...!잘게 썰은 고기와 우거지, 선지가 가득 들은 맑은 국물의 해장국. 밥이 말아져서 나온다. 뜨거운 음식 못 먹는 본인은,,, 밥이 말아져서 나와 먹는 것이 조금 힘들었다. 그래도 시원하고 맛있어서 술 한 잔 곁들이기도 좋다. 이전하기 전에 와 본적이 없어서 비교할 수는 없지만, 다른 해장국을 먹고 나서 추천 받을 때 들었던 극찬에 비해서는 약간 갸우뚱한 맛이었다. 뭔가 부족한데...? 하는 느낌이 좀 있었다. 육회는 뭐 늘 맛있으니 패스.맛있는, 특색있는 해장국 집임은 확실하나 약간의 아쉬움이 남았던 곳. 내 기대치가 너무 컸나? .. 그래도 종종 생각날 것 같다.\n",
      "\n",
      "index:  2007\n",
      "{'taste': 6.0, 'price': 3.302152852529602, 'service': 1.9999999999999998, 'atmosphere': 0.0}\n",
      "2017.12.03 방문 / 리코타팬케이크 단품 + 트리플치즈팬케이크 세트 + 꿀딸리요 + 오렌지주스 + 자몽에이드 주문폭신한 팬케이크가 먹고 싶을 때 다시 방문할 계획. 팬케이크가 먹고 싶을 때가 아니면 굳이 찾아가지는 않을 듯 하다.가게 분위기는 좋지만, 내부가 정말 작아서 웨이팅은 필수다. 4시쯤 갔더니 웨이팅은 적었으나 먹고 싶었던 양파 수프가 매진이었다ㅠㅠ 그리고 4시 30분쯤 되어서 재료 소진으로 마감하셨으니 너무 늦지 않게 찾아가길 추천한다. 사장님이 친절하시고 음식의 양도 많고, 주방도 오픈되어있어서 안심이었다. 팬케이크도 반죽부터 직접, 음료도 생과일을 직접 가신다. 그래서 시간이 좀 걸린다는 건 커버 가능한 단점.먹기 전에는 트리플 치즈 팬케이크를 조금 더 기대했는데, 실제로 먹어보니 너무 짜고 느끼한 감이 있었다. 치즈 들어간 음식을 좋아하는 편이었어서 더욱 당황함. 다만 취향의 차이일 수 있는 것이 동행한 남자친구는 이 쪽을 더 선호했다. 반면에 나는 리코타 치즈 팬케이크가 폭신하고 담백하면서도 은은하게 치즈 맛이 나서 훨씬 좋았고(딱 기대했던 맛), 동행인은 '너무 평범한 맛'이라고 평했다. 세트에서 베이컨이 짭쪼름하니 맛있었는데 - 특별한 맛은 아니지만 베이컨은 원래 맛있으니까 - 하나밖에 안나와서 다음엔 돈 주고 추가할 예정. 감자는 의외로 차가워서 좀 놀랐지만 기대만큼이었다. 꿀딸리요가 의외로 너무 괜찮았는데, 상큼하고 밸런스가 무척 좋았다. 딸기도 싱싱하고 다른 부재료도 과하지 않게 듬뿍 들어가서 재구매 확정! 음료들은 그냥... 그랬다. 가격 대비 좀 아쉽지만 목막히니 하나는 사야하는 맛.아, 양이 정말 많다. 나와 남친은 정말 뭘 많이 먹는 편인데 결국 남겼다. 처음 시킬 때는 '팬케이크~ 입가심도 안되는 쪼끄만거~' 이러다가 막상 나오니 너무 많았다. 근데 다시보니 엄청 많이 시키긴했네... 2인이 방문한다면 팬케이크 세트 하나 + 꿀딸리요 하나 + 음료 1~2잔 정도가 적당할 듯 하다.팬케이크를 참 좋아하는데, 집에서 해먹으면 양 조절도 어렵고 손도 많이 가서 잘 안해먹는데 괜찮은 집을 발견해서 기쁘다. 다음에는 양파 수프도 먹어볼 계획. 다만 팬케이크를 안좋아하지만 굳이 찾아가보거나, 매일 웨이팅을 기다리면서 자주 가 볼만큼은 아니니 참고.\n",
      "\n",
      "index:  2008\n",
      "{'taste': 1.0, 'price': -0.19047619047619047, 'service': 0.0, 'atmosphere': -0.19047619047619047}\n",
      "방문한지 햇수로 2년쯤 지난 곳인데도 여전히 맛있는 곳입니다. 4.8은 너무 높은 점수인가 싶긴해도 이정도 요리에 가격은 가로수길에서 찾아보기 힘든 곳이라 납득\n",
      "\n",
      "index:  2009\n",
      "{'taste': 5.861751323242641, 'price': 0.3867682371449863, 'service': 2.727272727272727, 'atmosphere': 2.0}\n",
      "정말 만족 ! 자리가 협소하여 웨이팅이 다소 길지만 날씨가 괜찮다면 기다려보는것도 나쁘지 않은 선택인 것 같다.가격대가 합리적이고 주메뉴도 맛있다.전체적으로 간이 세지않은 편이라 속이 편했다.가게에 들어갈때부터 나갈때까지 정말 친절하셔서 편안한 음식과 편안한 분위기 속에서 식사할 수 있어서 만족스러웠다 ☺️☺️ 재방문 의사도\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = 2000\n",
    "for i in range(start, start + 10):\n",
    "    print('index: ', i)\n",
    "    print(model.score_review(tokenize(data.review.iloc[i])))\n",
    "    print(data.review.iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}